
import os
import pandas as pd
from pathlib import Path
from snakemake.shell import shell

shell.executable("powershell.exe")

Papers = glob_wildcards("workdir/inputs/{text}.md").text
original_paper = glob_wildcards("workdir/expected_output/or{antimony}.txt").antimony

rule all:
    input:
        expand("workdir/fabric_output/{sample}.txt", sample=Papers),
        expand("workdir/expected_output/or{model}.txt", model=original_paper),
        #expand("workdir/csv_output/{sample}_result.csv", sample=Papers),
        expand("workdir/final_models/{sample}_tested.txt", sample=Papers),
        "workdir/all_simulations.csv",
        "workdir/all_semantic_comparison.csv",
        "workdir/test_table.csv"

rule conversion:
    input:
        "workdir/inputs/{sample}.md"

    output:
        "workdir/fabric_output/{sample}.txt"

    shell:
        "Type {input} | fabric -p Antimony_Converter > {output}" 

        
        #"Type {input} | fabric -p Antimony_Converter > {output}"
        #"fabric -p Antimony_Converter Type {input} > {output}"

rule first_decode:
    input:
        "workdir/fabric_output/{sample}.txt"  
    output:
        "workdir/decoded/{sample}_1dec.txt"
    run:
        with open(input[0], 'rb') as source_file:
            with open(output[0], 'w+b') as dest_file:
                contents = source_file.read()
                dest_file.write(contents.decode('utf-16').encode('utf-8'))
          

rule first_simulation:
    input:
        "workdir/decoded/{sample}_1dec.txt" 

    output: 
        "workdir/Error/{sample}_1er.txt",
        "workdir/simulated/{sample}_1S.txt"
    
    script:
        "scripts/check_simulation.py"

rule first_Evaluation:
    input:
        "workdir/Error/{sample}_1er.txt"
    
    output:
        "workdir/Evaluation/first/{sample}_1eval.csv"
    
    script:
        "scripts/Error_Evaluation_1.py"

rule first_aggregation:
    input:
        expand("workdir/Evaluation/first/{sample}_1eval.csv", sample=Papers)
    output:
        "workdir/CSV/first_evaluation.csv"
    run:
        import pandas as pd
        
        dfs = [pd.read_csv(file) for file in input]
        df = pd.concat(dfs, ignore_index=True)
        df.to_csv(output[0], index=False)


rule first_correction:
    input:
        model = "workdir/simulated/{sample}_1S.txt",
        error = "workdir/Error/{sample}_1er.txt"

    output:
        corrected_model = "workdir/corrected/{sample}_1C.txt"

    shell:
        "Cat {input.model}, {input.error} | fabric -p Antimony_Editor > {output.corrected_model}" 


rule second_decode:
   input:
        "workdir/corrected/{sample}_1C.txt"  
   output:
        "workdir/decoded/{sample}_2dec.txt"
   run:
        with open(input[0], 'rb') as source_file:
            with open(output[0], 'w+b') as dest_file:
                contents = source_file.read()
                dest_file.write(contents.decode('utf-16').encode('utf-8'))

rule second_simulation:
    input:
        "workdir/decoded/{sample}_2dec.txt" 

    output: 
        "workdir/Error/{sample}_2er.txt",
        "workdir/simulated/{sample}_2S.txt"
    
    script:
        "scripts/check_simulation.py"


rule second_Evaluation:
    input:
        "workdir/Error/{sample}_2er.txt"
    
    output:
        "workdir/Evaluation/second/{sample}_2eval.csv"
    
    script:
        "scripts/Error_Evaluation_2.py"

rule second_aggregation:
    input:
        expand("workdir/Evaluation/second/{sample}_2eval.csv",sample=Papers)
    output:
        "workdir/CSV/second_evaluation.csv"
    run:
        import pandas as pd
        
        dfs = [pd.read_csv(file) for file in input]
        df = pd.concat(dfs, ignore_index=True)
        df.to_csv(output[0], index=False)

rule second_correction:
    input:
        model = "workdir/simulated/{sample}_2S.txt"

    output:
        corrected_model = "workdir/corrected/{sample}_2C.txt"

    params:
        error = "workdir/Error/{sample}_2er.txt"

    shell:
        "Type {input.model} | fabric -p Antimony_Editor {params.error} > {output.corrected_model}" 

rule third_decode:
    input:
        "workdir/corrected/{sample}_2C.txt"  
    output:
        "workdir/decoded/{sample}_3dec.txt"
    run:
        with open(input[0], 'rb') as source_file:
            with open(output[0], 'w+b') as dest_file:
                contents = source_file.read()
                dest_file.write(contents.decode('utf-16').encode('utf-8'))

#Type {params.error} | fabric -p Antimony_Editor {input.model} > {output.corrected_model},
#        shell = "powershell"

#fabric -p Antimony_Editor Type {params.error} < {input.model} > {output.corrected_model},
#        shell = "powershell"

# third Simulation: the models coming from second correction will be copied in the ./final_model repository: it contains all tested model (corrected or not). In the end we are going to generate a final csv file with some info about each 
# model simulation (% of compiled and simulated model from first simulation without correction until the last one after the second correction).

rule third_simulation:
    input:
        "workdir/decoded/{sample}_3dec.txt" 

    output: 
        "workdir/Error/{sample}_3er.txt",
        "workdir/final_models/{sample}_tested.txt"
    
    script:
        "scripts/check_simulation.py"


rule third_Evaluation:
    input:
        "workdir/Error/{sample}_3er.txt"
    
    output:
        "workdir/Evaluation/third/{sample}_3eval.csv"
    
    script:
        "scripts/Error_Evaluation_3.py"

rule third_aggregation:
    input:
        expand("workdir/Evaluation/third/{sample}_3eval.csv",sample=Papers)
    output:
        "workdir/CSV/third_evaluation.csv"
    run:
        import pandas as pd
        
        dfs = [pd.read_csv(file) for file in input]
        df = pd.concat(dfs, ignore_index=True)
        df.to_csv(output[0], index=False)

rule aggregate_all:
    input:
        expand("workdir/CSV/{number}_evaluation.csv", number=["first","second","third"])

    output:
        "workdir/all_simulations.csv"

    run:
        import pandas as pd
        
        dfs = [pd.read_csv(file) for file in input]
        df = pd.concat(dfs, ignore_index=False, axis=1)
        df.to_csv(output[0], index=False)

rule semantic_evaluation_generated:
    input:
        "workdir/final_models/{sample}_tested.txt"
    
    output:
        "workdir/semantic_evaluation/generated/{sample}_G_semantic.csv"
    
    script:
        "scripts/semantic_evaluation.py"

rule semantic_evaluation_originals:
    input:
        "workdir/expected_output/or{model}.txt"
    
    output:
        "workdir/semantic_evaluation/original/{model}_O_semantic.csv"
    
    script:
        "scripts/semantic_evaluation.py"

rule merge_generated:
    input:
        expand("workdir/semantic_evaluation/generated/{sample}_G_semantic.csv",sample=Papers)
    output:
        "workdir/semantic_evaluation/Semantic_Outputs_generated.csv"
    run:
        import pandas as pd
        
        dfs = [pd.read_csv(file) for file in input]
        df = pd.concat(dfs, ignore_index=False, axis=0)
        df.to_csv(output[0], index=False)

rule merge_originals:
    input:
        expand("workdir/semantic_evaluation/original/{model}_O_semantic.csv", model=original_paper)
    output:
        "workdir/semantic_evaluation/Semantic_Outputs_original.csv"
    run:
        import pandas as pd
        
        dfs = [pd.read_csv(file) for file in input]
        df = pd.concat(dfs, ignore_index=False, axis=0)
        df.to_csv(output[0], index=False)

rule parameter_comparison:
    input:
        "workdir/semantic_evaluation/Semantic_Outputs_generated.csv",
        "workdir/semantic_evaluation/Semantic_Outputs_original.csv"
    
    output:
        "workdir/all_semantic_comparison.csv"
    
    script:
        "scripts/final_comparison.py"


rule evaluation_table:
    input:
        "workdir/all_simulations.csv",
        "workdir/all_semantic_comparison.csv"
    
    output:
        "workdir/test_table.csv"
    
    script:
        "scripts/test_table.py"


#rule third_simulation:
#    input:
#        "workdir/decoded/{sample}_3dec.txt"

#    output: 
#        result= "workdir/csv_output/{sample}_result.csv",
#        final_model = "workdir/final_models/{sample}_tested.txt"
    
#    params:
#        file = lambda wc : wc.sample
    
#    script:
#        "scripts/csv_creation.py"
     

# aggregate the result of each model in a final csv file!

#rule aggregate_result:
#    input:
#        expand("workdir/csv_output/{sample}_result.csv", sample=Papers)

#    output: "workdir/all_simulations.csv"
    
#    run:
#        import pandas as pd
#        dfs = [pd.read_csv(file) for file in input]
#        df = pd.concat(dfs, ignore_index=True)
#        df.to_csv(output[0], index=False)

 #fabric -p Antimony_Editor type \"{params.error}\" < \"{input.model}\" > \"{output.corrected_model}\",
        #shell = "powershell" 

        #"Type \"{params.error}\" < \"{input.model}\" | fabric -p Antimony_Editor > \'{output}\'"
        
        #"Type \"{input.model}\"; Type \"{input.error}\" | fabric -p Antimony_Editor > \"{output.corrected_model}\""

"""
rule aggregate_result:
    input:
        expand("workdir/Error/{sample}.sim{iter}.txt", sample=Papers, iter=range(0, Max_iter + 1))
    output:
        "workdir/all_simulations.csv"
    run:
        import os
        import re
        import pandas as pd

        models = set()
        results = []

        for filename in os.listdir("workdir/Error"):
            m = re.match(r"(.*)_sim(\d+)\.txt", filename)
            if m:
                models.add(m.group(1))

        for model in models:
            error_path = input[0] #f"errori/{model}_iter{MAX_ITER}.txt"
            if os.path.exists(f"workdir/simulated_models/{sample}.txt"):
                results.append({"nome_file": sample, "Simulation": True, "last_error": ""})
            else:
                last_error = open(error_path).read().strip() if os.path.exists(error_path) else "Unknown"
                results.append({"file_name": model, "Simulation": False, "last_error": last_error})

        df = pd.DataFrame(results)
        df.to_csv(output[0], index=False)

rule simulation:
    input:
        model="workdir/fabric_output/{sample}.txt",

    output:
        new_model="workdir/simulated/{sample}.txt",
        result="workdir/csv_output/{sample}_result.csv",
        attempt="workdir/attempt/{sample}_attempt.txt"  # se simula: generiamo un file csv che contenga (nome_modello, simulation = True)
    
    params:
        file = lambda wildcards: wildcards.sample 
                                                             # errore del modello quando non simula 
    script:
        "script/check_simulation.py"
        "Move-Item -Path \"{input.model}\" -Destination > \"{output.new_model}\""
         
rule moving_model:
    input:
        csv ="workdir/csv_output/{sample}_result.csv",
        model="workdir/simulated/{sample}.txt"
        
    output:
        well="workdir/simulated/well_simulated/{sample}.txt",
        wrong="workdir/simulated/wrong_simulated/{sample}.txt" 
    run:
        import os
        import pandas as pd
        import shutil
        dfs = [pd.read_csv(file) for file in input.csv]

        if dfs['simulation'].iloc[0] == True:
            shutil.move({input.model}, {output.well})
        else:
            shutil.move({input.model}, {output.wrong})


checkpoint check_number_simulation:
    output:
        rules.simulation.output.attempt

def input_for_aggregate(wildcards):
    with checkpoints.check_number_simulation.get(sample=wildcards.sample).output[0].open() as f:
        if f.read().strip() == "4":
            return rules.aggregate.output[0]
        else:
            return "workdir/csv_output/False/{sample}_result.csv"
    
rule check_false_simulation:
    input:
        "workdir/csv_output/{sample}_result.csv"
    output:
        false="workdir/csv_output/False/{sample}_result.csv"
    run:
        import os
        import shutil
        dfs = [pd.read_csv(file) for file in input]

        if dfs['simulation'].iloc[0] == False:
                shutil.move({input}, {output.false})


rule get_error:
    input:
        "workdir/csv_output/False/{sample}_result.csv"   
    output:
        error = "workdir/Error/{sample}.error.txt" 
    run:
        dfs = pd.read_csv(input)

        if dfs["error"].iloc[0]:
            error_value = dfs["error"].iloc[0]

        with open(output.error, "w") as f:
            f.write(str(error_value))
            f.close()

rule correction:
    input:
        model = "workdir/simulated/wrong_simulated/{sample}.txt",
        error = "workdir/Error/{sample}.error.txt",
        wrong_csv = "workdir/csv_output/False/{sample}_result.csv"
     
    output:
        correct_model = "workdir/fabric_output/{sample}.txt"

    shell:
        "Type \"{input.model}\" \"{input.error}\" | fabric -p Antimomy_Editor > \"{output.correct_model}\""
        "Remove-Item  \"{input.model}\""
        "Remove-Item \"{input.error}\""
        "Remove-Item \"{input.wrong_csv}\""
        
rule aggregate:
    input:
        expand("workdir/csv_output/{sample}_result.csv", sample=Papers)

    output: "workdir/all_simulations.csv"
    
    run:
        import pandas as pd
        dfs = [pd.read_csv(file) for file in input]
        df = pd.concat(dfs, ignore_index=True)
        df.to_csv(output[0], index=False)

"""       

